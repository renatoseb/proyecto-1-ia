{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "CUTS = 10\n",
    "PREDICT_V = 'ClassId'\n",
    "FILE_NAME = f'./data_{N_CLASSES}_{CUTS}_cuts.csv'\n",
    "data = pd.read_csv(FILE_NAME)\n",
    "print(f'{FILE_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalize(data):\n",
    "    X = data.iloc[:,:-2]        # feature columns\n",
    "    X = (X-X.mean())/X.std()    # normalize data\n",
    "\n",
    "    Y = data.iloc[:,-2:-1]      # predict variable column\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA REPORTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reporting(X, Y):\n",
    "    n, c = X.shape\n",
    "    print(f'Training examples: {n}')\n",
    "    for i in range(N_CLASSES):\n",
    "        d0 = data[data[PREDICT_V] == i]\n",
    "        r, c = d0.shape\n",
    "        print(f'\\tClass-id {i} : {r} \\t{round(r*100/n)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_reporting(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_Fold_Validation(classifier, X, Y):\n",
    "    # get K folds index\n",
    "    folds = 10\n",
    "    kf = KFold(n_splits=folds)\n",
    "    kf.get_n_splits(X)\n",
    "    k_fold_mean_score = 0\n",
    "\n",
    "    model = classifier\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        model = classifier\n",
    "        model.fit(X.loc[train_index], Y.loc[train_index].values.ravel())\n",
    "        predict = model.predict(X.loc[test_index])\n",
    "        \n",
    "        k_fold_mean_score += accuracy_score(Y.loc[test_index], predict)    \n",
    "\n",
    "    k_fold_mean_score /= folds\n",
    "    print(f'k-fold mean error:   {1 - k_fold_mean_score}')\n",
    "    print(f'k-fold mean score:   {k_fold_mean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bootstrap_Validation(classifier, X, Y, K=7):\n",
    "    E = 10\n",
    "    kf = KFold(n_splits=E)\n",
    "    kf.get_n_splits(X)\n",
    "\n",
    "    indexes = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        indexes.append(np.array(test_index))\n",
    "    indexes = np.array(indexes, dtype=object)\n",
    "    bootstrap = 0\n",
    "    for i in range(E):\n",
    "        idx = np.random.choice(E, K, replace=True)\n",
    "        not_idx = [i for i in range(E) if i not in idx]\n",
    "\n",
    "        train_idx = np.concatenate(indexes[idx], axis=None)\n",
    "        test_idx = np.concatenate(indexes[not_idx], axis=None)\n",
    "        # print(idx, not_idx)\n",
    "\n",
    "        model = classifier\n",
    "        model.fit(X.loc[train_idx], Y.loc[train_idx].values.ravel())\n",
    "        predict = model.predict(X.loc[test_idx])\n",
    "        \n",
    "        bootstrap += accuracy_score(Y.loc[test_idx], predict)\n",
    "    bootstrap /= E\n",
    "    print(f'bootstrap mean error:   {1 - bootstrap}')\n",
    "    print(f'bootstrap mean score:   {bootstrap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier():\n",
    "    def __init__(self, model, dataset):\n",
    "        self.file_name = dataset\n",
    "        self.X, self.Y = get_normalize(pd.read_csv(dataset).sample(frac=1).reset_index(drop=True))\n",
    "        self.model = model\n",
    "\n",
    "    \n",
    "    def experiment(self):\n",
    "        print(f'\\t {type(self.model)}')\n",
    "        print(f'\\t....Working on {self.file_name} .csv file')\n",
    "        PRODUCTION_MODEL = self.model\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(self.X, self.Y, test_size=0.3)\n",
    "        PRODUCTION_MODEL.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "        print(f'accuracy score: {PRODUCTION_MODEL.score(X_test, Y_test)}')\n",
    "        \n",
    "        K_Fold_Validation(self.model, self.X, self.Y)\n",
    "        Bootstrap_Validation(self.model, self.X, self.Y)\n",
    "        # CONFUSSION MATRIX\n",
    "        # cm = confusion_matrix(Y_test, PRODUCTION_MODEL.predict(X_test))\n",
    "\n",
    "        # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=PRODUCTION_MODEL.classes_)\n",
    "        # disp.plot()\n",
    "\n",
    "        # cm_normalize = normalize(cm, norm='l1')\n",
    "        # disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalize, display_labels=PRODUCTION_MODEL.classes_)\n",
    "        # disp.plot()\n",
    "\n",
    "        # # ACCURACY REPORT FOR EACH CLASS\n",
    "        # arr = np.array(cm)\n",
    "        # for i in range(N_CLASSES):\n",
    "        #     print(f'\\taccuracy on class {i}-th: {round(arr[i,i]/np.sum(arr[i,:]), 5)} %')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(dual=False)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "model.fit(X_train, Y_train.values.ravel())\n",
    "acc_score = model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'accuracy score: {acc_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confussion matrix\n",
    "cm = confusion_matrix(Y_test, model.predict(X_test))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "cm_normalize = normalize(cm, norm='l1')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalize, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# accuracy report for each class\n",
    "arr = np.array(cm)\n",
    "for i in range(N_CLASSES):\n",
    "    print(f'\\taccuracy on class {i}-th: {round(arr[i,i]/np.sum(arr[i,:]), 5)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_Fold_Validation(LinearSVC(dual=False), X, Y)\n",
    "Bootstrap_Validation(LinearSVC(dual=False), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "X = data.iloc[:,:-2]        # feature columns\n",
    "Y = data.iloc[:,-2:-1]      # predict variable column\n",
    "\n",
    "# normalize data\n",
    "X = (X-X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_Fold_Validation(LinearSVC(dual=False), X, Y)\n",
    "Bootstrap_Validation(LinearSVC(dual=False), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "\t....Working on ./data_5_20_cuts.csv .csv file\n",
      "accuracy score: 0.7501924557351809\n",
      "k-fold mean error:   0.21323499179003869\n",
      "k-fold mean score:   0.7867650082099613\n",
      "bootstrap mean error:   0.28006894054086184\n",
      "bootstrap mean score:   0.7199310594591382\n",
      "\t <class 'sklearn.svm._classes.LinearSVC'>\n",
      "\t....Working on ./data_5_20_cuts.csv .csv file\n",
      "accuracy score: 0.5354118552732872\n",
      "k-fold mean error:   0.4595106062021921\n",
      "k-fold mean score:   0.5404893937978079\n",
      "bootstrap mean error:   0.4632363185485373\n",
      "bootstrap mean score:   0.5367636814514627\n",
      "\t <class 'sklearn.svm._classes.SVC'>\n",
      "\t....Working on ./data_5_20_cuts.csv .csv file\n",
      "accuracy score: 0.43033102386451116\n",
      "k-fold mean error:   0.5568902268085277\n",
      "k-fold mean score:   0.44310977319147227\n",
      "bootstrap mean error:   0.5625644242105409\n",
      "bootstrap mean score:   0.43743557578945913\n",
      "\t <class 'sklearn.svm._classes.SVC'>\n",
      "\t....Working on ./data_5_20_cuts.csv .csv file\n",
      "accuracy score: 0.5816012317167052\n",
      "k-fold mean error:   0.42543446047871425\n",
      "k-fold mean score:   0.5745655395212858\n",
      "bootstrap mean error:   0.4357428759304808\n",
      "bootstrap mean score:   0.5642571240695192\n"
     ]
    }
   ],
   "source": [
    "class_list = [5, 10]\n",
    "cut_list = [20, 10, 5, 4, 3, 2]\n",
    "\n",
    "models = [KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree', leaf_size=30), LinearSVC(dual=False), SVC(kernel='poly'), SVC(kernel='linear')]\n",
    "\n",
    "for m in models:\n",
    "    for c in class_list:\n",
    "        for n_cut in cut_list:\n",
    "            engine = Classifier(model=m, dataset=f'./data_{c}_{n_cut}_cuts.csv')\n",
    "            engine.experiment()\n",
    "            break\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a22cf861add1ece0adc0944127aff8d229012544a4d27df8683a924f9388ca2f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
